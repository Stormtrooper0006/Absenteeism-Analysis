# Absenteeism-Analysis

# ğŸ“Š Data Workflow Overview

This project illustrates a typical workflow in a Business Intelligence (BI) and Data Science (DS) collaboration. In this project, I assume the role of the BI Analyst.

---

## ğŸ§© Roles and Responsibilities

### ğŸ”· BI Analyst Role (Pre-Model Phase)

- Preprocessing was performed on the historical dataset `absenteeism_data.csv` (700 rows) using Python.
- Tasks include data categorizing, dropping unnecessary column, etc..
- Documented in: `preprocessing/Absenteeism_Preprocessing.ipynb`

### ğŸ”· Data Science Team Role (Model Development)

After preprocessing, the dataset is assumed to be handed over to the Data Science team, who developed a machine learning model for absenteeism prediction. Their deliverables (included in this repository) are:

- `absenteeism_new_data.csv` â€” New, unseen data for prediction (40 rows).
- `absenteeism_module.py` â€” Python module containing the trained model logic.
- `model` â€” Serialized trained model file.
- `scaler` â€” Serialized preprocessing scaler used during training.
- `Absenteeism_Integration.ipynb` â€” Integration notebook demonstrating how to apply the model to new data.

### ğŸ”· BI Analyst Role (Post-Model Phase)

- The BI Analyst uses the model output (predictions) to derive business insights.
- Further analysis and visualization are done using SQL and Tableau.
- Dashboard View
  ![Absenteeism_Dashboard](https://github.com/user-attachments/assets/759696eb-b72f-43a4-97fb-8be9f2498fba)

---

## ğŸ’» Local Environment Setup (VS Code)

1. Install **Python 3.8**
2. Install **Visual C++ Build Tools**:

   - [Download here](https://visualstudio.microsoft.com/visual-cpp-build-tools/)
   - Select:
     - "Desktop Development with C++"
     - âœ” "C++ build tools"
     - âœ” "Windows 10 SDK" or "Windows 11 SDK" (depending on your system)

3. Open terminal (bash or PowerShell) and create a virtual environment:
   ```bash
   py -3.8 -m venv venv38
   ```
4. In VS Code:
   Press Ctrl+Shift+P â†’ "Python: Select Interpreter" â†’ Select venv38
5. Activate the virtual environment:
   ```bash
   source venv38/Scripts/activate
   ```
6. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
   If requirements.txt is not available, use the command below:
   ```bash
   pip install scikit-learn==0.22 ipykernel pandas==1.4.4 numpy==1.19.5 pymysql
   ```
   Alternatively:
   ```bash
   venv38/Scripts/python.exe -m pip install scikit-learn==0.22 ipykernel pandas==1.4.4 numpy==1.19.5 pymysql
   ```
7. Set up the database:
   Run create_database.sql on your MySQL server to create the required database and table.

### ğŸ“¦ Saving Dependencies

To generate a requirements.txt file:

```bash
pip freeze > requirements.txt
```

---

## ğŸ“ Project Structure

```pgsql
â”œâ”€â”€ data/
â”‚   â””â”€â”€ processed/
â”‚   â””â”€â”€ raw/
â”œâ”€â”€ preprocessing/
â”‚   â””â”€â”€ model/
â”‚   â””â”€â”€ scaler/
â”œâ”€â”€ sql/
â””â”€â”€ tableau/
```

---

## ğŸ“Œ Notes

Ensure MySQL server is running before executing the integration.
